📄 README.md
# Gesture Lab ✋🤚📏

A **real-time web app** that tracks two hands using **MediaPipe** and a webcam.  
It visualizes **thumb–index finger distance**, **hand openness**, and recognizes **gestures** like 👍 Thumbs Up, ✌️ Peace, 👌 OK, ✊ Fist, 🖐️ Open, etc.  

The project runs entirely in the browser with **HTML + JavaScript** (no backend needed).

---

## ✨ Features
- 🎥 Live webcam feed with mirrored display  
- 🖐️ Dual-hand tracking with MediaPipe Hands  
- 📏 Real-time distance calculation (in pixels & cm) between thumb & index  
- 📊 Openness bar gauge for each hand  
- 🤟 Gesture recognition (Thumbs Up, Peace, OK, Fist, Open/Closed)  
- 🖼️ Visualization: hand landmarks, distance line, and info panel  

---

## 🚀 Demo
👉 (Add GIF or screenshot of your app running here)

---

## 🛠️ Tech Stack
- **HTML5 + CSS3 + JavaScript**  
- **MediaPipe Hands** (landmark detection)  
- **Canvas API** (drawing lines, markers, and overlays)  

---

## 📂 Project Structure


.
├── index.html # Main application file
└── README.md # Project documentation


---

## 🔧 Usage
1. Clone or download this repository:
   ```bash
   git clone https://github.com/your-username/gesture-lab.git
   cd gesture-lab


Open index.html in a browser (Chrome recommended).

Ensure your browser allows camera access.

Raise your hand ✋ and see:

Thumb–index distance line

Distance values (px / cm)

Openness gauge bar

Recognized gesture

📌 Applications

Human-computer interaction

Gesture-controlled interfaces

AR/VR input methods

Interactive learning tools

🤝 Contributing

Feel free to fork this repo and add more gestures, improve UI, or extend features!

📜 License

This project is licensed under the MIT License – see the LICENSE
 file for details.


---

⚡ Do you want me to also make you a **GIF demo script** (using `ffmpeg` or a browser recording → optimized GIF) so you can easily add a **demo preview** to your GitHub?
