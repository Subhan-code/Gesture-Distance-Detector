ğŸ“„ README.md
# Gesture Lab âœ‹ğŸ¤šğŸ“

A **real-time web app** that tracks two hands using **MediaPipe** and a webcam.  
It visualizes **thumbâ€“index finger distance**, **hand openness**, and recognizes **gestures** like ğŸ‘ Thumbs Up, âœŒï¸ Peace, ğŸ‘Œ OK, âœŠ Fist, ğŸ–ï¸ Open, etc.  

The project runs entirely in the browser with **HTML + JavaScript** (no backend needed).

---

## âœ¨ Features
- ğŸ¥ Live webcam feed with mirrored display  
- ğŸ–ï¸ Dual-hand tracking with MediaPipe Hands  
- ğŸ“ Real-time distance calculation (in pixels & cm) between thumb & index  
- ğŸ“Š Openness bar gauge for each hand  
- ğŸ¤Ÿ Gesture recognition (Thumbs Up, Peace, OK, Fist, Open/Closed)  
- ğŸ–¼ï¸ Visualization: hand landmarks, distance line, and info panel  

---

## ğŸš€ Demo
ğŸ‘‰ (Add GIF or screenshot of your app running here)

---

## ğŸ› ï¸ Tech Stack
- **HTML5 + CSS3 + JavaScript**  
- **MediaPipe Hands** (landmark detection)  
- **Canvas API** (drawing lines, markers, and overlays)  

---

## ğŸ“‚ Project Structure


.
â”œâ”€â”€ index.html # Main application file
â””â”€â”€ README.md # Project documentation


---

## ğŸ”§ Usage
1. Clone or download this repository:
   ```bash
   git clone https://github.com/your-username/gesture-lab.git
   cd gesture-lab


Open index.html in a browser (Chrome recommended).

Ensure your browser allows camera access.

Raise your hand âœ‹ and see:

Thumbâ€“index distance line

Distance values (px / cm)

Openness gauge bar

Recognized gesture

ğŸ“Œ Applications

Human-computer interaction

Gesture-controlled interfaces

AR/VR input methods

Interactive learning tools

ğŸ¤ Contributing

Feel free to fork this repo and add more gestures, improve UI, or extend features!

ğŸ“œ License

This project is licensed under the MIT License â€“ see the LICENSE
 file for details.


---

âš¡ Do you want me to also make you a **GIF demo script** (using `ffmpeg` or a browser recording â†’ optimized GIF) so you can easily add a **demo preview** to your GitHub?
